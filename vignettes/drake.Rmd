---
title: "drake"
subtitle: "where to begin"
author: "William Michael Landau"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    number_sections: true
vignette: >
  %\VignetteIndexEntry{drake}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = F}
suppressMessages(suppressWarnings(library(drake)))
suppressMessages(suppressWarnings(library(magrittr)))
unlink(".drake", recursive = TRUE)
clean(destroy = TRUE, verbose = FALSE)
unlink(c("Makefile", "report.Rmd", "shell.sh", "STDIN.o*", "Thumbs.db"))
knitr::opts_chunk$set(
  collapse = TRUE,
  error = TRUE,
  warning = TRUE
)
```

![](logo-vignettes.png)

This tutorial is the abridged version of the [quickstart vignette](https://github.com/ropensci/drake/blob/master/vignettes/quickstart.Rmd). For more information, see the [documentation website](https://ropensci.github.io/drake/), which includes the [rendered online version of the quickstart vignette](https://ropensci.github.io/drake/articles/quickstart.html).

```{r precleangetstarteddrake, echo = FALSE}
# Remove any previous work.
clean(destroy = TRUE)
```

# The motivation of the basic example

Is there an association between the weight and the fuel efficiency of cars? To find out, we use the `mtcars` dataset from the `datasets` package. The `mtcars` dataset originally came from the 1974 Motor Trend US magazine, and it contains design and performance data on 32 models of automobile.

```{r mtcarsdrake1}
# ?mtcars # more info
head(mtcars)
```

Here, `wt` is weight in tons, and `mpg` is fuel efficiency in miles per gallon. We want to figure out if there is an association between `wt` and `mpg`. The `mtcars` dataset itself only has 32 rows, so we generate two larger bootstrapped datasets and then analyze them with regression models. We summarize the regression models to see if there is an association.

# A taste of `drake`'s basic example

Your workspace begins with a bunch of imports: functions, pre-loaded data objects, and saved files available before the real work begins.

```{r drakeimportdrakermd}
load_basic_example(verbose = FALSE) # Get the code with drake_example("basic").

# Drake looks for data objects and functions in your R session environment
ls()

# and saved files in your file system.
list.files()
```

Your real work is outlined in a data frame of data analysis steps called "targets". The targets depend on the imports, and `drake` will figure out how they are all connected.

```{r myplandrakevig}
my_plan
```

Wildcard templating generates these data frames at scale.

```{r drake_plangeneration}
library(magrittr)
dataset_plan <- drake_plan(
  small = simulate(5),
  large = simulate(50)
)
dataset_plan

analysis_methods <- drake_plan(
  regression = regNUMBER(dataset__) # nolint
) %>%
  evaluate_plan(wildcard = "NUMBER", values = 1:2)
analysis_methods

analysis_plan <- plan_analyses(
  plan = analysis_methods,
  datasets = dataset_plan
)
analysis_plan

whole_plan <- rbind(dataset_plan, analysis_plan)
whole_plan
```

Using static code analysis, `drake` detects the dependencies of all your targets. The result is an interactive network diagram.

```{r drakevisgraph, eval = FALSE}
vis_drake_graph(my_plan)
```

<iframe
src = "https://cdn.rawgit.com/ropensci/drake/0b76e536/images/outdated.html"
width = "100%" height = "600px" allowtransparency="true"
style="border: none; box-shadow: none">
</iframe>

At this point, all your targets are out of date because the project is new.

```{r outdateddrake}
config <- drake_config(my_plan, verbose = FALSE) # Master configuration list
outdated(config)
```

The `make()` function traverses the network and builds the targets that require updates.

```{r firstmakedrake}
make(my_plan)
```

For the `reg2()` model on the small dataset, the p-value on `x2` is so small that there may be an association between weight and fuel efficiency after all.

```{r getmtcarsanswer}
readd(coef_regression2_small)
```

The project is currently up to date, so the next `make()` does nothing.

```{r makeuptodatedrake}
make(my_plan)
```

But a nontrivial change in `reg2()` triggers updates to all the affected downstream targets.

```{r reg2makedrake}
reg2 <- function(d){
  d$x3 <- d$x ^ 3
  lm(y ~ x3, data = d)
}

make(my_plan)
```

```{r endofline_drake, echo = F}
clean(destroy = TRUE, verbose = FALSE)
unlink(c("Makefile", "report.Rmd", "shell.sh", "STDIN.o*", "Thumbs.db"))
```

# Built-in example projects

`Drake` has [built-in example projects](https://github.com/ropensci/drake/tree/master/inst/examples). You can generate the code files for an example with `drake_example()`, and you can list the available examples with `drake_examples()`. For instance, `drake_example("gsp")` generates the R script and R Markdown report for the built-in econometrics data analysis project. See below for the currently supported examples.

## Learn how to use `drake`.

- `basic`: A tiny, minimal example with the `mtcars` dataset to demonstrate how to use `drake`. Use `load_basic_example()` to set up the project in your workspace. The [quickstart vignette](https://github.com/ropensci/drake/blob/master/vignettes/quickstart.Rmd) is a parallel walkthrough of the same example. 
- `gsp`: A more concrete, practical example using real econometrics data. It explores the relationships between gross state product and other quantities, and it shows off `drake`'s ability to generate lots of reproducibly-tracked tasks with ease.
- `packages`: A concrete, practical example using data on R package downloads. It demonstrates how `drake` can refresh a project based on new incoming data without restarting everything from scratch.


## High-performance computing

- `Docker-psock`: demonstrates how to deploy targets to a [Docker container](https://www.docker.com/what-container) using a specialized PSOCK cluster.
- `Makefile-cluster`: uses [Makefiles](https://www.gnu.org/software/make/) to deploy targets to a generic cluster (configurable).
- `sge`: uses `"future_lapply"` parallelism to deploy targets to a [Sun/Univa Grid Engine](https://supcom.hgc.jp/english/utili_info/manual/uge.html) cluster. Other clusters are similar. See the [batchtools/inst/templates](https://github.com/mllg/batchtools/tree/master/inst/templates) and [future.batchtools/inst/templates](https://github.com/HenrikBengtsson/future.batchtools/tree/master/inst/templates) for more example `*.tmpl` template files.
- `slurm`: similar to `sge`, but for [SLURM](https://slurm.schedmd.com).
- `torque`: similar to `sge`, but for [TORQUE](http://www.adaptivecomputing.com/products/open-source/torque/).

Regarding the high-performance computing examples, there is no one-size-fits-all `*.tmpl` configuration file for any job scheduler, so we cannot guarantee that the above examples will work for you out of the box. To learn how to configure the files to suit your needs, you should make sure you understand how to use your job scheduler and [batchtools](https://github.com/mllg/batchtools).

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/generate_plans.R
\name{evaluate_plan}
\alias{evaluate_plan}
\title{Use wildcard templating to create a
workflow plan data frame from a template data frame.}
\usage{
evaluate_plan(plan, rules = NULL, wildcard = NULL, values = NULL,
  expand = TRUE, rename = expand, trace = FALSE,
  columns = "command")
}
\arguments{
\item{plan}{workflow plan data frame, similar to one produced by
\code{\link[=drake_plan]{drake_plan()}}}

\item{rules}{Named list with wildcards as names and vectors of
replacements
as values. This is a way to evaluate multiple wildcards at once.
When not \code{NULL}, \code{rules} overrules \code{wildcard} and
\code{values} if
not \code{NULL}.}

\item{wildcard}{character scalar denoting a wildcard placeholder}

\item{values}{vector of values to replace the wildcard
in the drake instructions. Will be treated as a character vector.
Must be the same length as \code{plan$command} if \code{expand} is
\code{TRUE}.}

\item{expand}{If \code{TRUE}, create a new rows in the workflow plan
data frame
if multiple values are assigned to a single wildcard.
If \code{FALSE}, each occurrence of the wildcard
is replaced with the next entry in the \code{values} vector,
and the values are recycled.}

\item{rename}{logical, whether to rename the targets
based on the values supplied for the wildcards
(based on \code{values} or \code{rules}).}

\item{trace}{logical, whether to add columns that
trace the wildcard expansion process. These new
columns indicate which targets were evaluated with which
wildcards.}

\item{columns}{character vector of names of columns
to look for and evaluate the wildcards.}
}
\value{
A workflow plan data frame with the wildcards evaluated.
}
\description{
The commands in workflow plan data frames can have
wildcard symbols that can stand for datasets, parameters, function
arguments, etc. These wildcards can be evaluated over a set of
possible values using \code{evaluate_plan}.
}
\details{
Specify a single wildcard with the \code{wildcard}
and \code{values} arguments. In each command, the text in
\code{wildcard} will be replaced by each value in \code{values}
in turn. Specify multiple wildcards with the \code{rules} argument,
which overrules \code{wildcard} and \code{values} if
not \code{NULL}. Here, \code{rules} should be a list with wildcards
as names and vectors of possible values as list elements.
}
\examples{
# Create the part of the workflow plan for the datasets.
datasets <- drake_plan(
  small = simulate(5),
  large = simulate(50))
# Create a template workflow plan for the analyses.
methods <- drake_plan(
  regression1 = reg1(dataset__),
  regression2 = reg2(dataset__))
# Evaluate the wildcards in the template
# to produce the actual part of the workflow plan
# that encodes the analyses of the datasets.
# Create one analysis for each combination of dataset and method.
evaluate_plan(methods, wildcard = "dataset__",
  values = datasets$target)
# Only choose some combinations of dataset and analysis method.
ans <- evaluate_plan(methods, wildcard = "dataset__",
  values = datasets$target, expand = FALSE)
ans
# For the complete workflow plan, row bind the pieces together.
my_plan <- rbind(datasets, ans)
my_plan
# Workflow plans can have multiple wildcards.
# Each combination of wildcard values will be used
# Except when expand is FALSE.
x <- drake_plan(draws = rnorm(mean = Mean, sd = Sd))
evaluate_plan(x, rules = list(Mean = 1:3, Sd = c(1, 10)))
# You can use wildcards on columns other than "command"
evaluate_plan(
  drake_plan(
    x = target("always", cpu = "any"),
    y = target("any", cpu = "always"),
    z = target("any", cpu = "any"),
    strings_in_dots = "literals"
  ),
  rules = list(always = 1:2),
  columns = c("command", "cpu")
)
# With the `trace` argument,
# you can generate columns that show how the wildcards
# were evaluated.
plan <- drake_plan(x = rnorm(n__), y = rexp(n__))
plan <- evaluate_plan(plan, wildcard = "n__", values = 1:2, trace = TRUE)
print(plan)
# With the `trace` argument,
# you can generate columns that show how the wildcards
# were evaluated. Then you can visualize the wildcard groups
# as clusters.
plan <- drake_plan(x = rnorm(n__), y = rexp(n__))
plan <- evaluate_plan(plan, wildcard = "n__", values = 1:2, trace = TRUE)
print(plan)
cache <- storr::storr_environment()
config <- drake_config(plan, cache = cache)
vis_drake_graph(config, group = "n__", clusters = "1")
vis_drake_graph(config, group = "n__", clusters = c("1", "2"))
make(plan, targets = c("x_1", "y_2"), cache = cache)
# Optionally cluster on columns supplied by `drake_graph_info()$nodes`.
vis_drake_graph(config, group = "status", clusters = "up to date")
}
